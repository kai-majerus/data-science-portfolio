{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7766de2c",
   "metadata": {},
   "source": [
    "# Analysis Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c862a97",
   "metadata": {},
   "source": [
    "**What is Topic Modelling?**\n",
    "\n",
    "Topic modelling is a method for finding a group of words (i.e. topics) from a collection of documents that best represents the information in the collection of text documents. It can also be thought of as a form of text mining - a way to obtain recurring patterns of words in textual data. The topics identified are crucial data points in helping a business figure out where to put their efforts in improving their product or services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11b4aa",
   "metadata": {},
   "source": [
    "**Project description**\n",
    "\n",
    "In this project, I will use Kmeans to cluser/group customer reviews from twitter data with the aim of identifying the main topics/ideas in the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce47f3d",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16e3dea",
   "metadata": {},
   "source": [
    "Human language data is a very unstructured form of data. Natural Language Toolkit (NLTK) is a library that provides preprocessing and modelling tools for text data. Some of the tools include, classification, tokenization, stemming, tagging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80727d76",
   "metadata": {},
   "source": [
    "# Loading and Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db87eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import re # remove regex\n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbd3edc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get multiple outputs in the same cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "## Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faaac635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21047\n"
     ]
    }
   ],
   "source": [
    "raw_data  = pd.read_csv(\"tweets.csv\",encoding = 'ISO-8859-1')\n",
    "print(len(raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c3f993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shivaji_takey</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>Please check what happens to this no 940417705...</td>\n",
       "      <td>['vodafonein']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarasberiwala</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>Network fluctuations and 4G Speed is pathetic....</td>\n",
       "      <td>['vodafonein']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chitreamod</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>This has been going on since 3rd... this absol...</td>\n",
       "      <td>['vodafonein']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sanjan_suman</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>@VodafoneIN  I have done my recharge of 555 on...</td>\n",
       "      <td>['vodafonein']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_nihsit</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>But when???Still I am not received any call fr...</td>\n",
       "      <td>['vodafonein']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        username        date  \\\n",
       "0  shivaji_takey  10-06-2020   \n",
       "1  sarasberiwala  10-06-2020   \n",
       "2     chitreamod  10-06-2020   \n",
       "3   sanjan_suman  10-06-2020   \n",
       "4       t_nihsit  10-06-2020   \n",
       "\n",
       "                                               tweet        mentions  \n",
       "0  Please check what happens to this no 940417705...  ['vodafonein']  \n",
       "1  Network fluctuations and 4G Speed is pathetic....  ['vodafonein']  \n",
       "2  This has been going on since 3rd... this absol...  ['vodafonein']  \n",
       "3  @VodafoneIN  I have done my recharge of 555 on...  ['vodafonein']  \n",
       "4  But when???Still I am not received any call fr...  ['vodafonein']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "775806aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21047\n"
     ]
    }
   ],
   "source": [
    "# check the number of unique tweets\n",
    "unique_text = df.tweet.unique()\n",
    "print(len(unique_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d249345d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you share me good plan and can tell me how can i port my network operator'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet'][444]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab8cf1a",
   "metadata": {},
   "source": [
    "So there are 21,047 tweets about Vodafone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f3b2b",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552db09",
   "metadata": {},
   "source": [
    "Text preprocessing is naturally different than classical numerical preprocessing. However, it is equally as important, if not more. Common preprocessing tasks are:\n",
    "\n",
    "- Lowercase\n",
    "- Dealing with numbers and punctuation\n",
    "- Removing \"stopwords\"\n",
    "- Tokenizing\n",
    "- Stemming or Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b01c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce64943",
   "metadata": {},
   "source": [
    "## Remove any @ mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34d765",
   "metadata": {},
   "source": [
    "Remove @ from all of the tweets so that our model does not try to interpret it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20517303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Please check what happens to this no 940417705...\n",
       "1    Network fluctuations and 4G Speed is pathetic....\n",
       "2    This has been going on since 3rd... this absol...\n",
       "3      I have done my recharge of 555 on 9709333370...\n",
       "4    But when???Still I am not received any call fr...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'] = np.vectorize(remove_pattern)(df['tweet'], \"@[\\w]*\")\n",
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc7bc5d",
   "metadata": {},
   "source": [
    "## Remove numbers and punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b4397",
   "metadata": {},
   "source": [
    "Punctuation is rarely respected in modern text forms (e.g. social media). Unless you can guarantee a proper use of punctuation across the entire dataset, it is better to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5dcf60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Please check what happens to this no          ...\n",
       "1    Network fluctuations and  G Speed is pathetic ...\n",
       "2    This has been going on since  rd    this absol...\n",
       "3      I have done my recharge of     on           ...\n",
       "4    But when   Still I am not received any call fr...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'] = df['Clean_text'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b50cbf",
   "metadata": {},
   "source": [
    "## Lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75809a74",
   "metadata": {},
   "source": [
    "Text modelling algorithms are case sensitive. Two words need to have the same casing to be considered the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73867b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        please check what happens to this no          ...\n",
       "1        network fluctuations and  g speed is pathetic ...\n",
       "2        this has been going on since  rd    this absol...\n",
       "3          i have done my recharge of     on           ...\n",
       "4        but when   still i am not received any call fr...\n",
       "                               ...                        \n",
       "21042    i sent u my contact no  but still did not get ...\n",
       "21043    dear   i have bn facing ur network problem for...\n",
       "21044    rubbish i made many time   you didn t resolved...\n",
       "21045    why the caller tunes sound so horrible  if a s...\n",
       "21046      what nonsense are u guys saying    i m getti...\n",
       "Name: Clean_text, Length: 21047, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Clean_text\"]= df[\"Clean_text\"].str.lower() \n",
    "df['Clean_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd3d85",
   "metadata": {},
   "source": [
    "## Remove whitespace and words of length 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87479410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    please check what happens this not woking sinc...\n",
       "1    network fluctuations and speed pathetic need j...\n",
       "2    this has been going since this absolutely unpr...\n",
       "3    have done recharge but haven got perday with u...\n",
       "4    but when still not received any call from cust...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'] = df['Clean_text'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbff4c",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dddb78c",
   "metadata": {},
   "source": [
    "Tokenizing means transforming a single string into a list of words, also called word tokens. For preprocessing tasks dealing with entire words, you will need to tokenize your text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248f63c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [please, check, what, happens, this, not, woki...\n",
       "1    [network, fluctuations, and, speed, pathetic, ...\n",
       "2    [this, has, been, going, since, this, absolute...\n",
       "3    [have, done, recharge, but, haven, got, perday...\n",
       "4    [but, when, still, not, received, any, call, f...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'] = df['Clean_text'].apply(lambda x: x.split())\n",
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0966b5b",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe725480",
   "metadata": {},
   "source": [
    "Lemmatizing is a technique used to find the root of words, in order to group them by meaning rather than exact form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7eb26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = lemmatized\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47327681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_text'] = df['Clean_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c9d64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [please, check, what, happens, this, not, woki...\n",
       "1    [network, fluctuation, and, speed, pathetic, n...\n",
       "2    [this, ha, been, going, since, this, absolutel...\n",
       "3    [have, done, recharge, but, haven, got, perday...\n",
       "4    [but, when, still, not, received, any, call, f...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "264fc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['Clean_text'])):\n",
    "    df['Clean_text'][i] = ' '.join(df['Clean_text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f05c48",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2da1fb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21047, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae53e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing any tweets with exactly duplicated text or tweets with no text\n",
    "df.drop_duplicates(subset=['Clean_text'], keep = 'first',inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e98c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after dropping duplicates, I reset the index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c55b20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19754, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa58150",
   "metadata": {},
   "source": [
    "## Indentifying special instances of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f3d2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for tweets with length 0\n",
    "df['Clean_text_length'] = df['Clean_text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f0cefc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>Clean_text</th>\n",
       "      <th>Clean_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>omanmessi</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>@VodafoneIN</td>\n",
       "      <td>['ooredoooman', 'vodafonein']</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username        date        tweet                       mentions  \\\n",
       "20  omanmessi  10-06-2020  @VodafoneIN  ['ooredoooman', 'vodafonein']   \n",
       "\n",
       "   Clean_text  Clean_text_length  \n",
       "20                             0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Clean_text_length']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d274f823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>mentions</th>\n",
       "      <th>Clean_text</th>\n",
       "      <th>Clean_text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>omanmessi</td>\n",
       "      <td>10-06-2020</td>\n",
       "      <td>@VodafoneIN</td>\n",
       "      <td>['ooredoooman', 'vodafonein']</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     username        date        tweet                       mentions  \\\n",
       "20  omanmessi  10-06-2020  @VodafoneIN  ['ooredoooman', 'vodafonein']   \n",
       "\n",
       "   Clean_text  Clean_text_length  \n",
       "20                             0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that this tweet with length 0 is not an artifact of previous preprocessing\n",
    "raw_data[raw_data['username']=='omanmessi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62c15f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([20], dtype='int64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can simply drop these tweets\n",
    "indexes = df[df['Clean_text_length']==0]['Clean_text'].index\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4860a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = indexes,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f72bc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19753 entries, 0 to 19753\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   username           19753 non-null  object\n",
      " 1   date               19753 non-null  object\n",
      " 2   tweet              19753 non-null  object\n",
      " 3   mentions           19753 non-null  object\n",
      " 4   Clean_text         19753 non-null  object\n",
      " 5   Clean_text_length  19753 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1f3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19753 entries, 0 to 19752\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   username           19753 non-null  object\n",
      " 1   date               19753 non-null  object\n",
      " 2   tweet              19753 non-null  object\n",
      " 3   mentions           19753 non-null  object\n",
      " 4   Clean_text         19753 non-null  object\n",
      " 5   Clean_text_length  19753 non-null  int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 926.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True,inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6732e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    please check what happens this not woking sinc...\n",
       "1    network fluctuation and speed pathetic need ji...\n",
       "2    this ha been going since this absolutely unpro...\n",
       "3    have done recharge but haven got perday with u...\n",
       "4    but when still not received any call from cust...\n",
       "Name: Clean_text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Clean_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161097a",
   "metadata": {},
   "source": [
    "# Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95148d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
